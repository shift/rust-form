// Auto-generated observability-enabled main.rs with OpenTelemetry and Prometheus
use axum::{
    extract::{Request, State},
    http::StatusCode,
    middleware,
    response::Json,
    routing::{get, post, put, delete},
    Router,
};
use std::{net::SocketAddr, sync::Arc, time::Duration};
use tower::ServiceBuilder;
use tower_http::{
    cors::CorsLayer,
    trace::TraceLayer,
    timeout::TimeoutLayer,
};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};
use prometheus::Registry;

// Generated modules
mod models;
mod handlers;
mod database;
mod error;
mod observability;
mod scaling;

pub use models::*;
pub use handlers::*;
pub use database::*;
pub use error::*;
pub use observability::*;
pub use scaling::*;

#[derive(Clone)]
pub struct AppState {
    pub db: sqlx::PgPool,
    {% if observability.prometheus.enabled %}
    pub metrics: Arc<AppMetrics>,
    pub metrics_registry: Arc<Registry>,
    {% endif %}
    {% if observability.opentelemetry.enabled %}
    pub tracer: Arc<opentelemetry::global::BoxedTracer>,
    {% endif %}
    {% if scaling.enabled %}
    pub service_discovery: Arc<ServiceDiscovery>,
    pub load_balancer: Arc<LoadBalancer>,
    {% endif %}
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Load configuration
    dotenvy::dotenv().ok();
    let config = load_configuration().await?;

    {% if observability.opentelemetry.enabled %}
    // Initialize OpenTelemetry
    let otel_setup = OpenTelemetrySetup::new(config.observability.opentelemetry.clone());
    otel_setup.initialize().await?;
    
    tracing::info!(
        service.name = %config.observability.opentelemetry.service_name,
        service.version = %config.observability.opentelemetry.service_version,
        "OpenTelemetry initialized"
    );
    {% else %}
    // Initialize basic tracing
    tracing_subscriber::registry()
        .with(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "{{ project_name }}=debug,tower_http=debug".into()),
        )
        .with(tracing_subscriber::fmt::layer())
        .init();
    {% endif %}

    // Setup database connection pool
    let database_url = std::env::var("{{ database.url_env }}")
        .expect("{{ database.url_env }} must be set");
    let pool = setup_database(&database_url).await?;
    run_migrations(&pool).await?;

    {% if observability.prometheus.enabled %}
    // Initialize Prometheus metrics
    let metrics_registry = Arc::new(Registry::new());
    let app_metrics = Arc::new(AppMetrics::new(&metrics_registry)?);
    
    tracing::info!("Prometheus metrics initialized");
    {% endif %}

    {% if scaling.enabled %}
    // Initialize service discovery and load balancing
    let service_discovery = Arc::new(ServiceDiscovery::new(config.scaling.clone()).await?);
    let load_balancer = Arc::new(LoadBalancer::new(
        config.scaling.load_balancer.algorithm.clone(),
        service_discovery.clone(),
        config.scaling.load_balancer.circuit_breaker.clone(),
    ));

    // Register this instance
    service_discovery.register_instance().await?;
    tracing::info!("Service discovery initialized and instance registered");
    {% endif %}

    // Create application state
    let state = AppState {
        db: pool,
        {% if observability.prometheus.enabled %}
        metrics: app_metrics,
        metrics_registry,
        {% endif %}
        {% if observability.opentelemetry.enabled %}
        tracer: Arc::new(opentelemetry::global::tracer("{{ project_name }}")),
        {% endif %}
        {% if scaling.enabled %}
        service_discovery,
        load_balancer,
        {% endif %}
    };

    // Build application with observability
    let app = create_router_with_observability(state.clone());

    {% if scaling.enabled %}
    // Start auto-scaling if enabled
    if config.scaling.auto_scaling.enabled {
        let auto_scaler = AutoScaler::new(config.scaling.auto_scaling.clone());
        auto_scaler.start_monitoring().await;
        tracing::info!("Auto-scaling monitoring started");
    }
    {% endif %}

    // Start server
    let addr = SocketAddr::from(([0, 0, 0, 0], {{ server.port }}));
    tracing::info!(
        address = %addr,
        {% if observability.prometheus.enabled %}
        metrics_endpoint = "{{ observability.prometheus.endpoint }}",
        {% endif %}
        {% if health.enabled %}
        health_endpoint = "{{ health.endpoint }}",
        {% endif %}
        "Server starting with full observability"
    );

    let listener = tokio::net::TcpListener::bind(addr).await?;
    
    // Setup graceful shutdown
    let shutdown_signal = setup_shutdown_signal({% if scaling.enabled %}Some(state.service_discovery.clone()){% else %}None{% endif %});
    
    // Run server with graceful shutdown
    axum::serve(listener, app)
        .with_graceful_shutdown(shutdown_signal)
        .await?;

    {% if observability.opentelemetry.enabled %}
    // Cleanup OpenTelemetry
    otel_setup.shutdown().await?;
    {% endif %}

    Ok(())
}

fn create_router_with_observability(state: AppState) -> Router {
    let mut app = Router::new();

    // Main application routes
    {% for endpoint in api.endpoints %}
    app = app.route("{{ endpoint.path }}", {{ endpoint.method | lower }}({{ endpoint.handler }}));
    {% endfor %}

    {% if observability.prometheus.enabled %}
    // Prometheus metrics endpoint with authentication
    app = app.route(
        "{{ observability.prometheus.endpoint }}",
        get(PrometheusMetricsHandler::handle_metrics)
            {% if observability.prometheus.authentication.enabled %}
            .layer(middleware::from_fn_with_state(
                state.clone(),
                PrometheusMetricsHandler::auth_middleware
            ))
            {% endif %}
    );
    {% endif %}

    {% if health.enabled %}
    // Health check endpoint
    app = app.route("{{ health.endpoint }}", get(health_check_handler));
    
    // Readiness endpoint (for Kubernetes)
    app = app.route("/ready", get(readiness_check_handler));
    {% endif %}

    {% if scaling.enabled %}
    // Scaling management endpoints
    app = app.route("/admin/scaling/status", get(scaling_status_handler));
    app = app.route("/admin/scaling/instances", get(list_instances_handler));
    {% endif %}

    // Apply middleware stack with observability
    app = app.layer(
        ServiceBuilder::new()
            {% if observability.opentelemetry.tracing.enabled %}
            // OpenTelemetry tracing layer
            .layer(TraceLayer::new_for_http())
            {% endif %}
            {% if observability.prometheus.enabled %}
            // Prometheus metrics middleware
            .layer(middleware::from_fn_with_state(
                state.clone(),
                prometheus_metrics_middleware
            ))
            {% endif %}
            // Timeout layer
            .layer(TimeoutLayer::new(Duration::from_secs(30)))
            // CORS layer
            .layer(CorsLayer::permissive())
    );

    app.with_state(state)
}

{% if observability.prometheus.enabled %}
// Prometheus metrics middleware
async fn prometheus_metrics_middleware<B>(
    State(state): State<AppState>,
    request: Request<B>,
    next: axum::middleware::Next<B>,
) -> axum::response::Response {
    let start = std::time::Instant::now();
    let method = request.method().clone();
    let path = request.uri().path().to_string();

    // Increment request counter
    state.metrics.http_requests_total
        .with_label_values(&[method.as_str(), &path])
        .inc();

    // Execute request
    let response = next.run(request).await;

    // Record metrics
    let duration = start.elapsed().as_secs_f64();
    let status = response.status().as_u16().to_string();

    state.metrics.http_request_duration
        .with_label_values(&[method.as_str(), &path, &status])
        .observe(duration);

    // Update active connections gauge
    // This would be more sophisticated in a real implementation
    state.metrics.active_connections.set(1.0); // Placeholder

    response
}
{% endif %}

{% if health.enabled %}
// Health check handler
async fn health_check_handler(State(state): State<AppState>) -> Result<Json<HealthResponse>, StatusCode> {
    let health_checker = HealthChecker::new(/* health config */);
    
    match health_checker.check_health().await {
        Ok(health_status) => {
            let response = HealthResponse {
                status: health_status.overall_status,
                checks: health_status.checks.into_iter().map(|check| {
                    HealthCheckResponse {
                        name: check.name,
                        status: check.status,
                        duration_ms: check.duration.as_millis() as u64,
                        details: check.details,
                    }
                }).collect(),
                timestamp: health_status.timestamp,
                uptime_seconds: get_uptime_seconds(),
                version: env!("CARGO_PKG_VERSION").to_string(),
            };

            {% if observability.prometheus.enabled %}
            // Update health metrics
            for check in &response.checks {
                let status_value = match check.status {
                    CheckStatus::Healthy => 1.0,
                    CheckStatus::Warning(_) => 0.5,
                    CheckStatus::Unhealthy(_) => 0.0,
                };
                
                state.metrics.health_check_status
                    .with_label_values(&[&check.name])
                    .set(status_value);
            }
            {% endif %}

            Ok(Json(response))
        }
        Err(_) => Err(StatusCode::SERVICE_UNAVAILABLE),
    }
}

// Readiness check for Kubernetes
async fn readiness_check_handler(State(state): State<AppState>) -> StatusCode {
    // Basic readiness checks
    if state.db.is_closed() {
        return StatusCode::SERVICE_UNAVAILABLE;
    }

    StatusCode::OK
}
{% endif %}

{% if scaling.enabled %}
// Scaling status handler
async fn scaling_status_handler(State(state): State<AppState>) -> Result<Json<ScalingStatus>, StatusCode> {
    let instances = state.service_discovery.discover_instances().await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    let status = ScalingStatus {
        total_instances: instances.len(),
        healthy_instances: instances.iter().filter(|i| i.is_healthy()).count(),
        current_load: get_current_load().await,
        auto_scaling_enabled: true, // From config
        last_scaling_action: get_last_scaling_action().await,
    };

    Ok(Json(status))
}

// List instances handler
async fn list_instances_handler(State(state): State<AppState>) -> Result<Json<Vec<ServiceInstance>>, StatusCode> {
    let instances = state.service_discovery.discover_instances().await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(instances))
}
{% endif %}

// Graceful shutdown handling
async fn setup_shutdown_signal(
    {% if scaling.enabled %}
    service_discovery: Option<Arc<ServiceDiscovery>>
    {% else %}
    _: Option<()>
    {% endif %}
) {
    use tokio::signal;

    let ctrl_c = async {
        signal::ctrl_c()
            .await
            .expect("failed to install Ctrl+C handler");
    };

    #[cfg(unix)]
    let terminate = async {
        signal::unix::signal(signal::unix::SignalKind::terminate())
            .expect("failed to install signal handler")
            .recv()
            .await;
    };

    #[cfg(not(unix))]
    let terminate = std::future::pending::<()>();

    tokio::select! {
        _ = ctrl_c => {
            tracing::info!("Received Ctrl+C, starting graceful shutdown");
        },
        _ = terminate => {
            tracing::info!("Received SIGTERM, starting graceful shutdown");
        },
    }

    {% if scaling.enabled %}
    // Deregister from service discovery
    if let Some(discovery) = service_discovery {
        if let Err(e) = discovery.deregister_instance().await {
            tracing::error!(error = %e, "Failed to deregister service instance");
        }
    }
    {% endif %}

    tracing::info!("Graceful shutdown completed");
}

// Utility functions
fn get_uptime_seconds() -> u64 {
    static START_TIME: std::sync::OnceLock<std::time::Instant> = std::sync::OnceLock::new();
    let start = START_TIME.get_or_init(|| std::time::Instant::now());
    start.elapsed().as_secs()
}

async fn get_current_load() -> f64 {
    // Implementation would calculate current system load
    0.5 // Placeholder
}

async fn get_last_scaling_action() -> Option<chrono::DateTime<chrono::Utc>> {
    // Implementation would return last scaling action timestamp
    None
}

// Configuration loading
async fn load_configuration() -> anyhow::Result<Configuration> {
    // Load from rustform.yml and environment variables
    Configuration::load().await
}

// Response types
#[derive(serde::Serialize)]
struct HealthResponse {
    status: ServiceStatus,
    checks: Vec<HealthCheckResponse>,
    timestamp: chrono::DateTime<chrono::Utc>,
    uptime_seconds: u64,
    version: String,
}

#[derive(serde::Serialize)]
struct HealthCheckResponse {
    name: String,
    status: CheckStatus,
    duration_ms: u64,
    details: Option<serde_json::Value>,
}

{% if scaling.enabled %}
#[derive(serde::Serialize)]
struct ScalingStatus {
    total_instances: usize,
    healthy_instances: usize,
    current_load: f64,
    auto_scaling_enabled: bool,
    last_scaling_action: Option<chrono::DateTime<chrono::Utc>>,
}
{% endif %}